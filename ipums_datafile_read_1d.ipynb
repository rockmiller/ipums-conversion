{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the paths and filenames\n",
    "path = r'D:\\\\Projects\\\\ipums\\\\garrard_test\\\\'\n",
    "dataname = r'ky_garrard_1870_88v_test_usa_00006.dat'\n",
    "cbkname = r'ky_1870_cbk.pickle'\n",
    "sliceobjs = r'ky_1870_slice_objects.pickle'\n",
    "prefix = 'cn1870_'\n",
    "\n",
    "slice_objs = path + sliceobjs\n",
    "cbkfile = path + cbkname\n",
    "datafile = path + dataname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle functions\n",
    "def load_pickle(filename, objectname):\n",
    "        with open(path+filename, \"rb\") as infile:\n",
    "            objectname = pickle.load(infile)\n",
    "        print('Loaded from:', filename)\n",
    "\n",
    "def save_pickle(filename, objectname):\n",
    "    with open(path+filename, \"wb\") as outfile:\n",
    "        pickle.dump(objectname, outfile)\n",
    "    print('Saved to:',filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column_list:\n",
      " ['cn1870_year char(4)', 'cn1870_serial char(8)', 'cn1870_numprec char(2)', 'cn1870_subsamp char(2)', 'cn1870_numperhh char(4)', 'cn1870_hhtype char(1)', 'cn1870_region char(2)', 'cn1870_stateicp char(2)', 'cn1870_statefip char(2)', 'cn1870_countyicp char(4)']\n",
      "slice_list:\n",
      " [slice(0, 4, None), slice(4, 12, None), slice(12, 14, None), slice(14, 16, None), slice(16, 20, None), slice(20, 21, None), slice(21, 23, None), slice(23, 25, None), slice(25, 27, None), slice(27, 31, None)]\n"
     ]
    }
   ],
   "source": [
    "#loading the codebook and creating the lists of columns and slices\n",
    "cbk = pd.read_pickle(cbkfile)\n",
    "cbk.columns\n",
    "x = cbk['length'].astype('str')\n",
    "cbk['column_name'] = prefix+cbk['variable'].str.lower() + ' char('+x+')'\n",
    "column_list = cbk['column_name'].tolist()\n",
    "slice_list = cbk['slice_obj'].tolist()\n",
    "print('column_list:\\n',column_list[0:10])\n",
    "print('slice_list:\\n',slice_list[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_database(database):\n",
    "    conn = psycopg2.connect(dbname=database, user='postgres', password = '3701', host='localhost', port='5432')\n",
    "    return conn\n",
    "\n",
    "def create_cursor():\n",
    "    cursor = conn.cursor()\n",
    "    return cursor\n",
    "\n",
    "def set_census_schema():\n",
    "    cur.execute(\"SET SCHEMA 'census'\")\n",
    "\n",
    "def close_database():\n",
    "    conn.commit() #insert rollback logic\n",
    "    conn.close()\n",
    "\n",
    "def create_table(tablename, column_list):\n",
    "    columns_text = '(' + 'id serial PRIMARY KEY, ' + ' '.join(column_list) + ');'\n",
    "    print(columns)\n",
    "    cur.execute('DROP TABLE IF EXISTS ' + tablename + ';')\n",
    "    cur.execute('CREATE TABLE ' + tablename + ' ' + columns_text)\n",
    "    cur.execute('SELECT * FROM ' + tablename + ';') #to confirm table is created with correct column names\n",
    "\n",
    "def get_column_count(tablename, columns):\n",
    "    qry_cc = \n",
    "    '''\n",
    "    select count(*) from information_schema.columns\n",
    "    where table_name='<table_name>â€™;\n",
    "    '''\n",
    "    col_ct_sql = cur.execute(qry_cc)\n",
    "    col_ct_list = len(columns)+1\n",
    "    print('columns in table:',col_ct_sql,'\\n','columns in list:',col_ct_list)\n",
    "    \n",
    "def process_line(line, slices):\n",
    "    limit = len(line)\n",
    "    data = []\n",
    "    for i in slices:\n",
    "        len_slice = len(line[i])\n",
    "        begin = limit\n",
    "        limit = limit - len_slice\n",
    "        if limit <= 0: break\n",
    "        data.append(line[i])\n",
    "    return data\n",
    "\n",
    "def insert_tuple(tablename, data):\n",
    "    query = \"insert into \" + tablename + \" values %s returning *\"\n",
    "    cur.execute(query, (data,)) # notice the comma after the tuple\n",
    "    #query = \"\"\"\n",
    "    #    insert into table values %s\n",
    "    #    returning *\n",
    "    #\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the test database and define a cursor  \n",
    "conn = open_database('test')\n",
    "cur = create_cursor()\n",
    "set_census_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_table('census_1870',col_list)\n",
    "#get_column_counts('census_1870,col_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records processed: 10\n"
     ]
    }
   ],
   "source": [
    "records = 10\n",
    "rec_count = 0\n",
    "with open(datafile) as f:\n",
    "    for i in range(records):\n",
    "        line = f.readline()\n",
    "        if line == \"\": break\n",
    "        data = tuple(process_line(line, slice_list))\n",
    "        #insert_tuple('census', data)\n",
    "        rec_count += 1\n",
    "        ##print('processed',rec_count,'record')\n",
    "        #print(data)\n",
    "print('Total records processed:', rec_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opening a connection\n",
    "Connect to an existing database\n",
    ">>> conn = psycopg2.connect(\"dbname=test user=postgres\")\n",
    "\n",
    "#### Open a cursor to perform database operations\n",
    ">>> cur = conn.cursor()\n",
    "\n",
    "#### Execute a command: this creates a new table\n",
    ">>> cur.execute(\"CREATE TABLE test (id serial PRIMARY KEY, num integer, data varchar);\")\n",
    "\n",
    "\n",
    "#### Inserting the tuples as a single value\n",
    "\n",
    "query = \"\"\"\n",
    "    insert into t values %s\n",
    "    returning *\n",
    "\"\"\"\n",
    "my_tuple = (2, 'b')\n",
    "\n",
    "cursor.execute(query, (my_tuple,)) # Notice the comma after my_tuple\n",
    "rs = cursor.fetchall()\n",
    "conn.commit()\n",
    "for row in rs:\n",
    "    print row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "database",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
