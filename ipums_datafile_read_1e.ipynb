{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing Libraries and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'D:\\\\Projects\\\\ipums\\\\garrard_test\\\\'\n",
    "dataname = r'ky_garrard_1870_88v_test_usa_00006.dat'\n",
    "cbkname = r'ky_1870_cbk.pickle'\n",
    "prefix = 'cn1870_'\n",
    "table_name = 'census_1870'\n",
    "cbkfile = path + cbkname\n",
    "datafile = path + dataname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle functions\n",
    "def load_pickle(filename, objectname):\n",
    "        with open(path+filename, \"rb\") as infile:\n",
    "            objectname = pickle.load(infile)\n",
    "        print('Loaded from:', filename)\n",
    "\n",
    "def save_pickle(filename, objectname):\n",
    "    with open(path+filename, \"wb\") as outfile:\n",
    "        pickle.dump(objectname, outfile)\n",
    "    print('Saved to:',filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Codebook and Creating the Slice List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice_list:\n",
      " [slice(0, 4, None), slice(4, 12, None), slice(12, 14, None), slice(14, 16, None), slice(16, 20, None), slice(20, 21, None), slice(21, 23, None), slice(23, 25, None), slice(25, 27, None), slice(27, 31, None)]\n"
     ]
    }
   ],
   "source": [
    "cbk = pd.read_pickle(cbkfile)\n",
    "x = cbk['length'].astype('str')\n",
    "slice_list = cbk['slice_obj'].tolist()\n",
    "print('slice_list:\\n',slice_list[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database Functions (psycog2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_database(database):\n",
    "    conn = psycopg2.connect(dbname=database, user='postgres', password = '3701', host='localhost', port='5432')\n",
    "    return conn\n",
    "\n",
    "def create_cursor():\n",
    "    cursor = conn.cursor()\n",
    "    return cursor\n",
    "\n",
    "def set_census_schema():\n",
    "    cursor.execute(\"SET SCHEMA 'census'\")\n",
    "\n",
    "def close_database():\n",
    "    conn.commit() #insert rollback logic\n",
    "    conn.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_line(line, slices):\n",
    "    limit = len(line)\n",
    "    data = []\n",
    "    for i in slices:\n",
    "        len_slice = len(line[i])\n",
    "        begin = limit\n",
    "        limit = limit - len_slice\n",
    "        if limit <= 0: break\n",
    "        data.append(line[i])\n",
    "    return data\n",
    "\n",
    "def insert_tuple(tablename, ph, tupledata):\n",
    "    query = r\"insert into \" + tablename + \" values \" + ph + \"returning *\"\n",
    "    print(query)\n",
    "    cursor.execute(query, (tupledata,))\n",
    "    rs = cursor.fetchall()\n",
    "    conn.commit()\n",
    "    for row in rs:\n",
    "        print (row)\n",
    "    #cursor.execute(query, (data,)) # notice the comma after the tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cursor.execute(\"ROLLBACK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = open_database('test')\n",
    "cursor = create_cursor()\n",
    "set_census_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the Datafile (line by line) and Upload it to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input (\n",
    "#p = process from zero (set rec_count=0) - are you sure? This will wipe out resume data (y = proceed, anything else = repeat input)\n",
    "#r = read json, resume from (processed_count + 1) - - starting from record # (processed_count). are you sure?\n",
    "#x = break\n",
    "#else = repeat input loop)\n",
    "rec_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#convert to a while loop. Break out either at end of # of (count) of cycles = records, or at the end of file (line == \"\")\n",
    "#maybe itertools?\n",
    "with open(datafile) as f: # convert to iterator with itertools\n",
    "    for i in range(records): # exclude this line if you are using a while loop (it's a wrapper); or maybe use itertools.count()\n",
    "        line = f.readline() # this pulls the next line.\n",
    "        if line == \"\": break # or if end of #records reached\n",
    "        data = tuple(process_line(line, slice_list))\n",
    "        print(type(data),data)\n",
    "        total_fields = (len(data))\n",
    "        ph = r'%s '*total_fields\n",
    "        #insert_tuple(table_name, ph, data)\n",
    "        rec_count += 1      \n",
    "#while loop goes at the bottom - if endpoint is true, pass result, increment and break. If endpoint is false, repeat (while) loop.\n",
    "print('Total fields:',total_fields)\n",
    "print('Total records processed:', rec_count)\n",
    "#save rec_count as processed_count in the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "record number: 1\n",
      "skipped\n",
      "record number: 2\n",
      "skipped\n",
      "record number: 3\n",
      "skipped\n",
      "record number: 4\n",
      "skipped\n",
      "record number: 5\n",
      "skipped\n",
      "record number: 6\n",
      "skipped\n",
      "record number: 7\n",
      "skipped\n",
      "record number: 8\n",
      "skipped\n",
      "record number: 9\n",
      "<class 'tuple'> ('1870', '02095399', '06', '13', '0006', '2', '32', '51', '21', '0810', '2100810', '1', '000', '0000', '0000', '0000000', '01', '1', '0000000', '0001597', '840', '1', '0', '000', '00', '1', '02', '0', '1', '0', '0', '00073261', '0006', '2F3F2E08-B1F6-4876-A9AD-0ABCE5DEDAA6', '0003', '01', '05', '00', '0', '0', '00', '0', '0', '00', '0', '0', '0', '0', '99', '99', '10', '1001', '10', '1', '002', '99', '00', '1868', '1', '1', '100', '0', '000', '021', '02100', '1', '0', '0', '1', '0', '0', '0999', '999', '000', '00000000', '00000000', '03', 'EEEA2A48-4968-4392-9766-D28B1727C59D', '01', '                     ', '0', '0', '0', '0', '0', '0', '0', '3.0-1.1')\n",
      "record number: 10\n",
      "<class 'tuple'> ('1870', '02095399', '06', '13', '0006', '2', '32', '51', '21', '0810', '2100810', '1', '000', '0000', '0000', '0000000', '01', '1', '0000000', '0001597', '840', '1', '0', '000', '00', '1', '02', '0', '1', '0', '0', '00073261', '0006', '2F3F2E08-B1F6-4876-A9AD-0ABCE5DEDAA6', '0004', '01', '05', '00', '0', '0', '00', '0', '0', '00', '0', '0', '0', '0', '99', '99', '10', '1001', '10', '1', '000', '06', '12', '1870', '1', '1', '100', '0', '000', '021', '02100', '1', '0', '0', '1', '0', '0', '0999', '999', '000', '00000000', '00000000', '03', '530EFE4C-FCC7-4778-8C5D-95CE54A255E7', '01', '                     ', '0', '0', '0', '0', '0', '0', '0', '3.0-1.1')\n",
      "record number: 11\n",
      "<class 'tuple'> ('1870', '02095399', '06', '13', '0006', '2', '32', '51', '21', '0810', '2100810', '1', '000', '0000', '0000', '0000000', '01', '1', '0000000', '0001597', '840', '1', '0', '000', '00', '1', '02', '0', '1', '0', '0', '00073261', '0006', '2F3F2E08-B1F6-4876-A9AD-0ABCE5DEDAA6', '0005', '01', '05', '00', '0', '0', '00', '0', '0', '00', '0', '0', '0', '0', '99', '99', '10', '1001', '10', '2', '049', '99', '00', '1821', '1', '1', '100', '0', '000', '021', '02100', '1', '0', '0', '1', '4', '1', '0306', '985', '000', '00000000', '00000000', '03', '12DE5310-D918-47AA-B144-54685050EF05', '01', '                     ', '0', '0', '0', '0', '0', '0', '0', '3.0-1.1')\n",
      "record number: 12\n",
      "<class 'tuple'> ('1870', '02095399', '06', '13', '0006', '2', '32', '51', '21', '0810', '2100810', '1', '000', '0000', '0000', '0000000', '01', '1', '0000000', '0001597', '840', '1', '0', '000', '00', '1', '02', '0', '1', '0', '0', '00073261', '0006', '2F3F2E08-B1F6-4876-A9AD-0ABCE5DEDAA6', '0006', '02', '01', '00', '0', '0', '00', '0', '0', '00', '0', '0', '0', '0', '99', '99', '12', '1201', '12', '1', '050', '99', '00', '1820', '1', '1', '100', '0', '000', '039', '03900', '1', '2', '0', '1', '4', '2', '0142', '582', '488', '00000000', '00000000', '03', 'FB6B9F62-CF7A-4211-A698-1A6E6C923390', '02', '                     ', '0', '0', '0', '0', '0', '0', '0', '3.0-1.1')\n",
      "Total fields: 88\n",
      "Start record: 9\n",
      "End record: 12\n",
      "Total records processed: 4\n"
     ]
    }
   ],
   "source": [
    "#filename - first a scalar, then a list to process more (* in a directory, or list of filenames)\n",
    "#records are the number of records to process in this cycle (capped at the end of file)\n",
    "rec_count = 1\n",
    "processed_count = 0\n",
    "records = 4\n",
    "end_range = processed_count + 1 + records\n",
    "# now proceeding to process the records\n",
    "with open(datafile) as f: \n",
    "    while (rec_count < end_range):\n",
    "        line = f.readline() # this pulls the next line.\n",
    "        if line == \"\": break\n",
    "        print ('record number:',rec_count)\n",
    "        if (rec_count) <= processed_count:\n",
    "            print('skipped')\n",
    "            rec_count += 1\n",
    "            continue\n",
    "        data = tuple(process_line(line, slice_list))\n",
    "        print(type(data),data)\n",
    "        total_fields = (len(data))\n",
    "        ph = r'%s '*total_fields\n",
    "        #insert_tuple(table_name, ph, data)\n",
    "        rec_count += 1\n",
    "print('Total fields:',total_fields)\n",
    "print('Start record:',processed_count+1)\n",
    "print('End record:',rec_count-1)\n",
    "print('Total records processed:', (rec_count - processed_count - 1))\n",
    "#save rec_count as processed_count in the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commit and Close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting the tuples as a single value  \n",
    "\n",
    "query = \"\"\"  \n",
    "    insert into t values %s  \n",
    "    returning *  \n",
    "\"\"\"\n",
    "my_tuple = (2, 'b')  \n",
    "\n",
    "cursor.execute(query, (my_tuple,)) # Notice the comma after my_tuple  \n",
    "rs = cursor.fetchall()  \n",
    "conn.commit()  \n",
    "for row in rs:  \n",
    "    print row  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "database",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
