{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing Libraries and Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'D:\\\\Projects\\\\ipums\\\\garrard_test\\\\'\n",
    "dataname = r'ky_garrard_1870_88v_test_usa_00006.dat'\n",
    "cbkname = r'ky_1870_cbk.pickle'\n",
    "prefix = 'cn1870_'\n",
    "table_name = 'census_1870'\n",
    "cbkfile = path + cbkname\n",
    "datafile = path + dataname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pickle functions\n",
    "def load_pickle(filename, objectname):\n",
    "        with open(path+filename, \"rb\") as infile:\n",
    "            objectname = pickle.load(infile)\n",
    "        print('Loaded from:', filename)\n",
    "\n",
    "def save_pickle(filename, objectname):\n",
    "    with open(path+filename, \"wb\") as outfile:\n",
    "        pickle.dump(objectname, outfile)\n",
    "    print('Saved to:',filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the Codebook and Creating the Slice List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice_list:\n",
      " [slice(0, 4, None), slice(4, 12, None), slice(12, 14, None), slice(14, 16, None), slice(16, 20, None), slice(20, 21, None), slice(21, 23, None), slice(23, 25, None), slice(25, 27, None), slice(27, 31, None)]\n"
     ]
    }
   ],
   "source": [
    "cbk = pd.read_pickle(cbkfile)\n",
    "x = cbk['length'].astype('str')\n",
    "slice_list = cbk['slice_obj'].tolist()\n",
    "print('slice_list:\\n',slice_list[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database Functions (psycog2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_database(database):\n",
    "    conn = psycopg2.connect(dbname=database, user='postgres', password = '3701', host='localhost', port='5432')\n",
    "    return conn\n",
    "\n",
    "def create_cursor():\n",
    "    cursor = conn.cursor()\n",
    "    return cursor\n",
    "\n",
    "def set_census_schema():\n",
    "    cursor.execute(\"SET SCHEMA 'census'\")\n",
    "\n",
    "def close_database():\n",
    "    conn.commit() #insert rollback logic\n",
    "    conn.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_line(line, slices):\n",
    "    limit = len(line)\n",
    "    data = []\n",
    "    for i in slices:\n",
    "        len_slice = len(line[i])\n",
    "        begin = limit\n",
    "        limit = limit - len_slice\n",
    "        if limit <= 0: break\n",
    "        data.append(line[i])\n",
    "    return data\n",
    "\n",
    "def insert_row(tablename, ph, row):\n",
    "    query = r\"INSERT INTO \" + tablename + \" VALUES (\" + ph + \") \"\n",
    "    print('executing the insert')\n",
    "    cursor.execute(query, row)\n",
    "    print('committing the record')\n",
    "    #rs = cursor.fetchall()\n",
    "    conn.commit()\n",
    "    #for r in rs:\n",
    "        #print(r)\n",
    "    #cursor.execute(query, (data,)) # notice the comma after the tuple\n",
    "\n",
    "def clear_table(tablename):\n",
    "    clear = 'DELETE FROM ' + tablename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cursor.execute(\"ROLLBACK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = open_database('test')\n",
    "cursor = create_cursor()\n",
    "set_census_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the Datafile (line by line) and Upload it to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input sequence\n",
    "#filename - first a scalar, then a list to process more (* in a directory, or list of filenames)\n",
    "#input (\n",
    "#p = process from zero (set rec_count=1) - are you sure? This will wipe out resume data (y = proceed, anything else = repeat input)\n",
    "#r = read json for filename (revert to p if not available), resume from (processed_count + 1) - \"are you sure?\"\n",
    "#x = break\n",
    "#else = repeat input loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing record 1\n",
      "<class 'list'> ['1870', '02095398', '06', '50', '0006', '1', '32', '51', '21', '0810', '2100810', '1', '000', '0000', '0000', '0000000', '01', '1', '0000000', '0001597', '840', '1', '0', '000', '00', '2', '01', '1', '1', '1', '0', '00073260', '0006', 'A9AEFCA0-B1B4-48F5-AF1E-88D9FF8B6460', '0001', '01', '06', '00', '0', '0', '00', '0', '0', '02', '1', '4', '0', '0', '26', '18', '01', '0101', '01', '1', '050', '99', '00', '1820', '1', '1', '100', '0', '000', '021', '02100', '1', '3', '0', '1', '1', '2', '0005', '100', '105', '00000400', '00000245', '03', 'A9AEFCA0-B1B4-48F5-AF1E-88D9FF8B6460', '01', 'qkNIx5kHEM6Up-GCglGJH', '1', '1', '1', '0', '0', '0', '0', '3.0-1.1']\n",
      "executing the insert\n",
      "committing the record\n",
      "Total fields: 88\n",
      "Start record: 1\n",
      "End record: 1\n",
      "Total records processed: 1\n"
     ]
    }
   ],
   "source": [
    "# set up by the input sequence\n",
    "rec_count = 1\n",
    "processed_count = 0\n",
    "records = 1\n",
    "end_range = processed_count + 1 + records\n",
    "\n",
    "# now proceeding to process the records\n",
    "with open(datafile) as f: \n",
    "    while (True):\n",
    "        line = f.readline() # this pulls the next line.\n",
    "        if line == \"\": break\n",
    "        if (rec_count >= end_range and records != 0): break\n",
    "        if (rec_count) <= processed_count:\n",
    "            print('skipping record',rec_count)\n",
    "            rec_count += 1\n",
    "            continue\n",
    "        print ('processing record',rec_count)\n",
    "        data = process_line(line, slice_list)\n",
    "        print(type(data),data)\n",
    "        total_fields = (len(data))\n",
    "        ph = r'%s, '*(total_fields-1) + '%s'\n",
    "        insert_row(table_name, ph, data)\n",
    "        rec_count += 1\n",
    "print('Total fields:',total_fields)\n",
    "print('Start record:',processed_count+1)\n",
    "print('End record:',rec_count-1)\n",
    "print('Total records processed:', (rec_count - processed_count - 1))\n",
    "#save rec_count as processed_count in the json file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commit and Close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting the tuples as a single value  \n",
    "\n",
    "query = \"\"\"  \n",
    "    insert into t values %s  \n",
    "    returning *  \n",
    "\"\"\"\n",
    "my_tuple = (2, 'b')  \n",
    "\n",
    "cursor.execute(query, (my_tuple,)) # Notice the comma after my_tuple  \n",
    "rs = cursor.fetchall()  \n",
    "conn.commit()  \n",
    "for row in rs:  \n",
    "    print row  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "database",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
